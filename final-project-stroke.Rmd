---
title: "INFO 523 Final Project"
author: "Group 4: Sione Lister and Yanyan Dong"
date: "2022-11-16"
output: html_document
---

- [1. Introduction](#1)
- [2. Preparation](#2)
- [3. Data Cleaning](#3)
- [4. Exploratory Data Analysis](#4)
- [5. Model 1: Support Vector Machine](#5)
- [6. Model 2: K-nearest Neighbors](#6)
- [7. Model 3: Logistic Regression](#7)
- [8. Model Evaluation](#8)
- [9. Conclusion](#9)

-------------------

### <span id="1">1. Introduction</span>

#### Problem Description and Objectives
According to the World Health Organization, stroke is the second leading cause of death globally and, according to the Heart Disease and Stroke Statistics 2019 report, stroke is the fifth leading cause of death in the United States. Additionally, the most recent HDSS report shows that someone has a stroke in the United States every 40 seconds and someone dies from a stroke every 3.5 minutes. Due to the prevalence and seriousness of the heart disease condition, being able to predict one’s likelihood of suffering from a stroke prior could be helpful in assessing risk and evaluating treatment plans accordingly. 

Using the “healthcare-dataset-stroke-data” from Kaggle, we are curious to see which variables are associated with, first, a patient having a stroke and then second, if we can find a model to predict whether a patient will or will not have a stroke. While previous research shows that age, heart disease, average glucose level and hypertension are most important factors for stroke prediction, the dataset we are using contains all of these and also many other variables that may reveal interesting patterns. 

#### Dataset and Data Mining Task

The data we are using for this project is from Kaggle and contains 5,100 observations with twelve attributes: id, gender, age, if hypertension is present or not, if heart disease is present or not, if they have ever been married, what type of work they do, where they reside (rural or urban), their average glucose level, BMI, their smoking status and whether or not they had a stroke. Each row of data corresponds to one patient:

#### Attribute Information

1) id: unique identifier

2) gender: "Male", "Female" or "Other"

3) age: age of the patient

4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension

5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease

6) ever_married: "No" or "Yes"

7) work_type: "children", "Govt_jov", "Never_worked", "Private" or "Self-employed"

8) Residence_type: "Rural" or "Urban"

9) avg_glucose_level: average glucose level in blood

10) bmi: body mass index

11) smoking_status: "formerly smoked", "never smoked", "smokes" or "Unknown"*

12) stroke: 1 if the patient had a stroke or 0 if not

#### Link of dataset:
https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

-------------------

### <span id="2">2. Preparation</span>

```{r package, message=FALSE, warning=FALSE}
# data
library(dplyr)
library(ggplot2)
library(Amelia)
library(corrplot)
library(corrgram)

# model
library(caTools)
library(e1071)
library(caret)
library(ROSE)
library(Metrics)
library(class)
library(tidymodels)
library(glmnet)
```

```{r}
# read the data
data <- read.csv("healthcare-dataset-stroke-data.csv")

# view the data
head(data)
str(data)
summary(data)
```

-------------------

### <span id="3">3. Data Cleaning</span>

```{r}
# check NA values
any(is.na(data)) # it shows there are no missing value

# however there are N/A in bmi, convert them to NA values
data[data == 'N/A'] <- NA
missmap(data, col=c("yellow", "black"), legend=FALSE) # there are missing values on bmi
table(is.na(data)) # there are 201 missing values

# convert bmi data type to numeric
data$bmi <- as.numeric(data$bmi)

# plot bmi
hist(data$bmi)
boxplot(data$bmi)

# drop NA values
data <- na.omit(data)
any(is.na(data)) # check again, there is no NA value now

# drop the id column
data <- data[-1]
head(data)
```

```{r}
# data transformation
str(data)

# convert character data type to factor
data <- data %>% mutate(across(where(is.character),factor))

# convert hypertension, heart_disease, stroke data type from integer to factor
data$hypertension <- as.factor(data$hypertension)
data$heart_disease <- as.factor(data$heart_disease)
data$stroke <- as.factor(data$stroke)

# binning numeric valuables
# age
ggplot(data, aes(age,y=..density..)) + 
  geom_histogram(binwidth=1,
                 color="black",
                 fill="#02bcfa",
                 alpha=0.5) + 
  geom_density() + labs(title="Age Distribution")

boxplot(data$age)
summary(data$age)

# binning age with quantile: 25, 44, 60, 82
data$age <- cut(data$age,
                breaks = c(0, 25, 44, 60, 82), 
                labels=c('young', 'grown', 'mature', 'old'))

# avg glucose level
ggplot(data, aes(avg_glucose_level, y=..density..)) + 
  geom_histogram(color="black",
                 fill="#02bcfa",
                 alpha=0.5) + 
  geom_density() + 
  labs(title="Average Glucose Level Distribution")

boxplot(data$avg_glucose_level)
summary(data$avg_glucose_level)

# binning avg glucose level based on the information on website:
# https://my.clevelandclinic.org/health/diagnostics/12363-blood-glucose-test#:~:text=What%20is%20a%20normal%20glucose,can%20be%20%E2%80%9Cnormal%E2%80%9D%20too.
group_glucose <- function(level){
  res <- level
  for (i in 1:length(level)){
    if (level[i] <= 70){
      res[i] <- "low"
    } else if (level[i] > 70 & level[i] <= 99) {
      res[i] <- "normal"
    } else if (level[i] > 100 & level[i] <= 125) {
      res[i] <- "prediabetes"
    } else {
      res[i] <- "diabetes"
    }
  }
  return(res)
}

# apply group_glucose function
data$avg_glucose_level <- group_glucose(data$avg_glucose_level)

# convert avg_glucose_level data type to factor
data$avg_glucose_level <- as.factor(data$avg_glucose_level)

# levels of data$avg_glucose_level are in the wrong order
levels(data$avg_glucose_level)

# reorder the levels of data$avg_glucose_level
data$avg_glucose_level <- factor(data$avg_glucose_level, levels = c("low", "normal", "prediabetes", "diabetes"))

# check again
levels(data$avg_glucose_level)

# bmi
ggplot(data, aes(bmi)) + 
  geom_histogram(color="black",
                 fill="#02bcfa",
                 alpha=0.5) + 
  geom_density() + 
  labs(title="BMI Distribution")

boxplot(data$bmi)
summary(data$bmi)

# binning BMI based on the information on the CDC website:
# https://www.cdc.gov/healthyweight/assessing/index.html#:~:text=If%20your%20BMI%20is%20less,falls%20within%20the%20obese%20range.
group_bmi <- function(bmi){
  res <- bmi
  for (i in 1:length(bmi)){
    if (bmi[i] < 18.5){
      res[i] <- "underweight"
    } else if (bmi[i] >= 18.5 & bmi[i] <= 24.9) {
      res[i] <- "normal"
    } else if (bmi[i] >= 25.0 & bmi[i] <= 29.9) {
      res[i] <- "overweight"
    } else {
      res[i] <- "obese"
    }
  }
  return(res)
}

# apply group_bmi function
data$bmi <- group_bmi(data$bmi)

# convert bmi data type to factor
data$bmi <- as.factor(data$bmi)

# levels of data$bmi are in the wrong order
levels(data$bmi)

# reorder the levels of bmi
data$bmi <- factor(data$bmi, levels = c("underweight", "normal", "overweight", "obese"))

# reorder the levels of bmi
data$smoking_status <- factor(data$smoking_status, levels = c("never smoked", "Unknown", "formerly smoked", "smokes"))

# check the structure
str(data)
```

----------------

### <span id="4">4. Exploratory Data Analysis</span>

```{r}
# check the correlation
# convert factor variables to numeric variables
data_num <- data %>% mutate(across(where(is.factor),as.numeric))
str(data_num)

# correlation and corrplot
(cor <- cor(data_num))

# corrplot
corrplot(cor, method = "color")

# corrgram
corrgram(data_num, order = TRUE, 
         lower.panel = panel.shade,
         upper.panel = panel.pie,
         text.panel = panel.txt)
```

```{r}
# Age Group Distribution
ggplot(data, aes(age)) + 
  geom_bar(aes(fill = age)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Age", y = "Count", title ="Age Group Distribution")

# age & stroke
ggplot(data, aes(age)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Age", y = "Count", title ="Age Group Distribution with Class Label")

# normalize the height
ggplot(data, aes(age)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Age", y = "Scaled Count", title ="Age Distribution with Normalize Height")
```

```{r}
# Gender Distribution
ggplot(data, aes(gender)) + 
  geom_bar(aes(fill = gender)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Gender", y = "Count", title ="Gender Distribution")

# gender & stroke
ggplot(data, aes(gender)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Gender", y = "Count", title ="Gender Distribution with Class Label")

# normalize the height
ggplot(data, aes(gender)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Gender", y = "Scaled Count", title ="Gender Distribution with Normalize Height")
```

```{r}
# Hypertension Distribution
ggplot(data, aes(hypertension)) + 
  geom_bar(aes(fill = hypertension)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Hypertension", y = "Count", title ="Hypertension Distribution")

# hypertension & stroke
ggplot(data, aes(hypertension)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Hypertension", y = "Count", title ="Hypertension Distribution with Class Label")

# normalize the height
ggplot(data, aes(hypertension)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Hypertension", y = "Scaled Count", title ="Hypertension Distribution with Normalize Height")
```

```{r}
# Heart Disease Distribution
ggplot(data, aes(heart_disease)) + 
  geom_bar(aes(fill = heart_disease)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Heart Disease", y = "Count", title ="Heart Disease Distribution")

# heart_disease & stroke
ggplot(data, aes(heart_disease)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Heart Disease", y = "Count", title ="Heart Disease Distribution with Class Label")

# normalize the height
ggplot(data, aes(heart_disease)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Heart Disease", y = "Scaled Count", title ="Heart Disease Distribution with Normalize Height")
```

```{r}
# Marital Status
ggplot(data, aes(ever_married)) + 
  geom_bar(aes(fill = ever_married)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Marital Status", y = "Count", title ="Marital Status")

# ever_married & stroke
ggplot(data, aes(ever_married)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Marital Status", y = "Count", title ="Marital Status with Class Label")

# normalize the height
ggplot(data, aes(ever_married)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Marital Status", y = "Scaled Count", title ="Marital Status with Normalize Height")
```

```{r}
# Distribution of Work Type
ggplot(data, aes(work_type)) + 
  geom_bar(aes(fill = work_type)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Work Type", y = "Count", title ="Distribution of Work Type")

# work_type & stroke
ggplot(data, aes(work_type)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Work Type", y = "Count", title ="Distribution of Work Type with Class Label")

# normalize the height
ggplot(data, aes(work_type)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Work Type", y = "Scaled Count", title ="Distribution of Work Type with Normalize Height")
```

```{r}
# Distribution of Residence Type
ggplot(data, aes(Residence_type)) + 
  geom_bar(aes(fill = Residence_type)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Residence Type", y = "Count", title ="Distribution of Residence Type")

# Residence_type & stroke
ggplot(data, aes(Residence_type)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Residence Type", y = "Count", title ="Distribution of Residence Type with Class Label")

# normalize the height
ggplot(data, aes(Residence_type)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Residence Type", y = "Scaled Count", title ="Distribution of Residence Type with Normalize Height")
```

```{r}
# Group of Average Glucose Level
ggplot(data, aes(avg_glucose_level)) + 
  geom_bar(aes(fill = avg_glucose_level)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Average Glucose Level", y = "Count", title ="Group of Average Glucose Level")

# avg_glucose_level & stroke
ggplot(data, aes(avg_glucose_level)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Average Glucose Level", y = "Count", title ="Distribution of Average Glucose Level Group with Class Label")

# normalize the height
ggplot(data, aes(avg_glucose_level)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Average Glucose Level", y = "Scaled Count", title ="Group of Average Glucose Level with Normalize Height")
```

```{r}
# Distribution of BMI Group
ggplot(data, aes(bmi)) + 
  geom_bar(aes(fill = bmi)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "BMI Group", y = "Count", title ="Distribution of BMI Group")

# bmi & stroke
ggplot(data, aes(bmi)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "BMI Group", y = "Count", title ="Distribution of BMI Group with Class Label")

# normalize the height
ggplot(data, aes(bmi)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "BMI Group", y = "Scaled Count", title ="BMI Group with Normalize Height")
```

```{r}
# Distribution of Smoking Status
ggplot(data, aes(smoking_status)) + 
  geom_bar(aes(fill = smoking_status)) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Smoking Status", y = "Count", title ="Distribution of Smoking Status")

# smoking_status & stroke
ggplot(data, aes(smoking_status)) + 
  geom_bar(aes(fill = stroke)) +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(cols = vars(stroke)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.3) +
  labs(x = "Smoking Status", y = "Count", title ="Distribution of Smoking Status with Class Label")

# normalize the height
ggplot(data, aes(smoking_status)) + 
  geom_bar(aes(fill = stroke),
           position = "fill",
           alpha=0.8) +
  labs(x = "Smoking Status", y = "Scaled Count", title ="Distribution of Smoking Status with Normalize Height")
```

```{r}
# age, avg_glucose_level
ggplot(data, aes(age)) +
  geom_bar(alpha = 0.8, aes(fill = avg_glucose_level)) +
  facet_grid(rows = vars(avg_glucose_level)) +
  scale_fill_brewer(palette = "Reds") +
  geom_text(stat='count', aes(label=..count..)) +
  labs(x = "Age Group", y = "Count", title ="Distribution of Average Glucose Levels in Different Age Groups")

# age, hypertension
ggplot(data, aes(age)) +
  geom_bar(alpha = 0.8, aes(fill = hypertension)) +
  facet_grid(rows = vars(hypertension)) +
  scale_fill_manual(values = c("skyblue", "royalblue", "blue", "navy")) +
  geom_text(stat='count', aes(label=..count..)) +
  labs(x = "Age Group", y = "Count", title ="Hypertension Status in Different Age Groups")

# age, heart_disease
ggplot(data, aes(age)) +
  geom_bar(alpha = 0.8, aes(fill = heart_disease)) +
  facet_grid(rows = vars(heart_disease)) +
  scale_fill_manual(values = c("skyblue", "royalblue", "blue", "navy")) +
  geom_text(stat='count', aes(label=..count..)) +
  labs(x = "Age Group", y = "Count", title ="Heart Disease Status in Different Age Groups")

# age, bmi
ggplot(data, aes(age)) +
  geom_bar(alpha = 0.8, aes(fill = bmi)) +
  facet_grid(rows = vars(bmi)) +
  scale_fill_brewer(palette = "Reds") +
  geom_text(stat='count', aes(label=..count..)) +
  labs(x = "Age Group", y = "Count", title ="BMI Group in Different Age Groups")

# avg_glucose_level, bmi, stroke
ggplot(data, aes(bmi, avg_glucose_level)) +
  geom_jitter(alpha = 0.6, aes(color = stroke), size =1) +
  facet_grid(rows = vars(stroke)) +
  labs(x = "BMI Group", y = "Group of Average Glucose Level", title ="Distribution of BMI & Average Glucose Level with Class Label")

# hypertension, avg_glucose_level, bmi
ggplot(data, aes(bmi, avg_glucose_level)) +
  geom_jitter(alpha = 0.6, aes(color = hypertension), size =1) +
  facet_grid(rows = vars(hypertension)) +
  labs(x = "BMI Group", y = "Group of Average Glucose Level", title ="Distribution of BMI & Average Glucose Level with Different Hypertension Status")
```

----------------

### <span id="5">5. Model 1: Support Vector Machine</span>

```{r}
# drop uncorrelated attributes: gender, Residence_type
data_drop <- select(data, -gender, -Residence_type)

# Random Over-Sampling
# move class label to 1st row on dataset
data_md <- data_drop[c(9:1)]

# over sampling data
data_os <- ovun.sample(stroke~., data=data_md, method = "over", p = 0.5, seed = 1)

# check the data after over sampling
str(data_os)
summary(data_os)
table(data_os$data$stroke)

# move class label (stroke) back to last row
data_os <- data_os$data[c(9:1)]

# Train and Test Split
set.seed(101)

split <- sample.split(data_os$stroke, SplitRatio = 0.7)
train <- subset(data_os, split == TRUE)
test <- subset(data_os, split == FALSE)
```

```{r}
# SVM
model_svm <- svm(stroke ~ ., data = train)

# check the model
summary(model_svm)

# use the model on test data to predict our label (stroke)
pred_svm <- predict(model_svm, test[1:8])

# check the model performance
confusionMatrix(pred_svm, 
                factor(test$stroke), 
                mode = "everything", 
                positive = "1")
```


```{r}
# Parameter tuning
# sampling method: 10-fold cross validation
# It takes a long time, so I comment here

# tune_res <- tune.svm(x = stroke ~., data = train,
#                      type = "C-classification",
#                      kernel = "radial",
#                      cost = c(1,10),
#                      gamma = c(0.1,1))
# tune_res

# set cost = 10, gamma = 1
model_svm <- svm(stroke ~ ., data = train,
                 kernel = 'radial',
                 cost = 10,
                 gamma = 1)

# apply the tuned SVM model on test data to predict class label (stroke)
pred_svm <- predict(model_svm,test[1:8])
```

----------------

### <span id="6">6. Model 2: K-nearest Neighbors</span>

```{r}
# KNN
# convert data type from factor to numeric
data_os_num <- data_os %>% mutate(across(where(is.factor),as.numeric))
data_os_num$stroke <- factor(data_os_num$stroke)
str(data_os_num)

# standardize the dataset except class label (stroke)
data_std <- scale(data_os_num[1:8])
head(data_std)

# check variance
var(data_std[,8])

# add label column (stroke) back
data_knn <- cbind(data_std, data_os_num[9])
head(data_knn)

# train and test split for KNN model
set.seed(101)
split_knn <- sample.split(data_knn$stroke, SplitRatio = 0.7)
train_knn <- subset(data_knn, split_knn == TRUE)
test_knn <- subset(data_knn, split_knn == FALSE)

# build KNN model
pred_knn <- knn(train_knn[1:8],
                test_knn[1:8],
                train_knn$stroke,
                k = 1)

# check the error rate
er_knn <- mean(test_knn$stroke != pred_knn)
er_knn
```

```{r}
# Parameter tuning
for (i in 1:10){
  set.seed(101)
  pred_knn <- knn(train_knn[1:8],
                  test_knn[1:8],
                  train_knn$stroke,
                  k=i)
  er_knn[i] <- mean(test_knn$stroke != pred_knn)
}

# elbow method
k <- 1:10
(df <- data.frame(er_knn, k))

ggplot(df, aes(k, er_knn)) + 
  geom_point() + 
  geom_line(lty="dotted",
            color="blue")

# set k = 1
pred_knn <- knn(train_knn[1:8],
                test_knn[1:8],
                train_knn$stroke,
                k = 1)
```

----------------

### <span id="7">7. Logistic Regression</span>

```{r}
# Logistic Regression 
model_log <- glm(formula = stroke ~ .,
                 family = binomial(logit), 
                 data = train)
summary(model_log)

# apply the model on test dataset
pred_log <- predict(model_log,
                    newdata = test,
                    type='response')

res_log <- ifelse(pred_log > 0.5, 1, 0)
```

----------------

### <span id="8">8. Model Evaluation</span>

```{r}
# Evaluate the performance of models

## 1. SVM model
## ROC curve
roc.curve(pred_svm, test$stroke)

## plot Confusion Matrix and evaluation metrics
confusionMatrix(pred_svm, 
                factor(test$stroke), 
                mode = "everything", 
                positive = "1")

## 2. KNN model
## ROC curve
roc.curve(pred_knn, test_knn$stroke)

## plot Confusion Matrix and evaluation metrics
confusionMatrix(pred_knn, 
                factor(test_knn$stroke), 
                mode = "everything", 
                positive="1")

## 3. Logistic Regression model
## ROC curve
roc.curve(res_log, test$stroke)

## plot Confusion Matrix and evaluation metrics
confusionMatrix(factor(res_log), 
                factor(test$stroke), 
                mode = "everything", 
                positive="1")
```

----------------

### <span id="9">9. Conclusion</span>

